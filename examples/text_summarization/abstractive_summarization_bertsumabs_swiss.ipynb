{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation.\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive Summarization using BertSumAbs on CNN/DailyMails Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to fine tune BERT for abstractive text summarization. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation.\n",
    "\n",
    "### Abstractive Summarization\n",
    "Abstractive summarization is the task of taking an input text and summarizing its content in a shorter output text. In contrast to extractive summarization, abstractive summarization doesn't take sentences directly from the input text, instead, rephrases the input text.\n",
    "\n",
    "### BertSumAbs\n",
    "\n",
    "BertSumAbs refers to an BERT-based abstractive summarization algorithm  in [Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345) with [published examples](https://github.com/nlpyang/PreSumm). It uses the pretrained BERT model as encoder and finetune both encoder and decoder on a specific labeled summarization dataset like [CNN/DM dataset](https://github.com/harvardnlp/sent-summary). \n",
    "\n",
    "The figure below shows the comparison of architecture of the original BERT model (left) and BERTSUM (right), which BertSumAbs is built upon. For BERTSUM, a input document is split into sentences, and [CLS] and [SEP] tokens are inserted before and after each sentence. This resulting sequence is followed by the summation of three kinds of embeddings for each token before feeding into the transformer layers. The positional embedding used in BertSumAbs enables input length of more than 512, which is the  maximum input length for BERT model. \n",
    "\n",
    "It should be noted that the architecture only shows the encoder part. For decoder, BertSumAbs also uses a transformer with multiple layers and random initialization. As pretrained weights are used in the encoder, there is a mismatch in encoder and decoder which may result in unstable finetuning. Therefore, in fine tuning, BertSumAbs uses seperate optimizers for encoder and decoder, each uses its own scheduling. In text generation, techniques like trigram blocking and beam search can be used to improve model accuracy.\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/BertForSummarization.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "It's recommended to run this notebook on GPU machines as it's very computationally intensive. Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of steps. If QUICK_RUN = False, the notebook takes about 5 hours to run on a VM with 4 16GB NVIDIA V100 GPUs. Finetuning costs around 1.5 hours and inferecing costs around 3.5 hour.  Better performance can be achieved by increasing the MAX_STEPS.\n",
    "\n",
    "* **ROUGE Evalation**: To run rouge evaluation, please refer to the section of compute_rouge_perl in [summarization_evaluation.ipynb](./summarization_evaluation.ipynb) for setup.\n",
    "\n",
    "* **Distributed Training**:\n",
    "Please note that the jupyter notebook only allows to use pytorch [DataParallel](https://pytorch.org/docs/master/nn.html#dataparallel). Faster speed and larger batch size can be achieved with pytorch [DistributedDataParallel](https://pytorch.org/docs/master/notes/ddp.html)(DDP). Script [abstractive_summarization_bertsum_cnndm_distributed_train.py](./abstractive_summarization_bertsum_cnndm_distributed_train.py) shows an example of how to use DDP.\n",
    "\n",
    "* **Mixed Precision Training**:\n",
    "Please note that by default this notebook doesn't use mixed precision training. Faster speed and larger batch size can be achieved when you set FP16 to True. Refer to  https://nvidia.github.io/apex and https://github.com/nvidia/apex) for details to use mixed precision training. Check the GPU model on your machine to see if it allows mixed precision training. Please also note that mixed precision inferencing is also enabled in the prediciton utility function. When you use mixed precision training and/or inferencing, the model performance can be slightly worse than the full precision mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/home/ubuntu'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"/home/ubuntu/git/german-bertabs\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.models.transformers.abstractive_summarization_bertsum import (\n",
    "    BertSumAbs,\n",
    "    BertSumAbsProcessor,\n",
    ")\n",
    "\n",
    "from utils_nlp.eval import compute_rouge_python\n",
    "\n",
    "from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import scrapbook as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we used for this notebook is CNN/DM dataset which contains the documents and accompanying questions from the news articles of CNN and Daily mail. The highlights in each article are used as summary. The dataset consits of ~289K training examples, ~11K valiation examples and ~11K test examples. The length of the news articles is 781 tokens on average and the summaries are of 3.75 sentences and 56 tokens on average.\n",
    "\n",
    "The significant part of data preprocessing only involve splitting the input document into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data path used to save the downloaded data file\n",
    "#DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = 100\n",
    "if not QUICK_RUN:\n",
    "    TOP_N = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 426k/426k [00:20<00:00, 20.5kKB/s]\n"
    }
   ],
   "source": [
    "#train_dataset, test_dataset = CNNDMSummarizationDataset(\n",
    "#    top_n=TOP_N, local_cache_path=DATA_PATH, prepare_extractive=False\n",
    "#)\n",
    "\n",
    "from utils_nlp.dataset.swiss import SwissSummarizationDataset\n",
    "train_dataset, test_dataset = SwissSummarizationDataset( top_n=TOP_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "80"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'src_txt', 'tgt', 'tgt_txt'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "# the cache path\n",
    "CACHE_PATH = TemporaryDirectory().name\n",
    "\n",
    "# model parameters\n",
    "MODEL_NAME = \"bert-base-german-cased\"\n",
    "MAX_POS = 768\n",
    "MAX_SOURCE_SEQ_LENGTH = 640\n",
    "MAX_TARGET_SEQ_LENGTH = 140\n",
    "\n",
    "# mixed precision setting. To enable mixed precision training, follow instructions in SETUP.md.\n",
    "FP16 = False\n",
    "if FP16:\n",
    "    FP16_OPT_LEVEL = \"O2\"\n",
    "\n",
    "# fine-tuning parameters\n",
    "# batch size, unit is the number of tokens\n",
    "BATCH_SIZE_PER_GPU = 1\n",
    "\n",
    "\n",
    "# GPU used for training\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "if NUM_GPUS > 0:\n",
    "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
    "else:\n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "# Learning rate\n",
    "LEARNING_RATE_BERT = 5e-4 / 2.0\n",
    "LEARNING_RATE_DEC = 0.05 / 2.0\n",
    "\n",
    "\n",
    "# How often the statistics reports show up in training, unit is step.\n",
    "REPORT_EVERY = 250\n",
    "SAVE_EVERY = 5000\n",
    "\n",
    "# total number of steps for training\n",
    "MAX_STEPS = 1000\n",
    "\n",
    "if not QUICK_RUN:\n",
    "    MAX_STEPS = 10e6\n",
    "\n",
    "WARMUP_STEPS_BERT = 2000\n",
    "WARMUP_STEPS_DEC = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b2895f090c4f509c94bacf514c3c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7a1de5f35941309861f7a7f377e6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5a65d8666f40efa3861a8b7224ed63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# processor which contains the colloate function to load the preprocessed data\n",
    "processor = BertSumAbsProcessor(cache_dir=CACHE_PATH, max_src_len=MAX_SOURCE_SEQ_LENGTH, max_tgt_len=MAX_TARGET_SEQ_LENGTH)\n",
    "# summarizer\n",
    "summarizer = BertSumAbs(\n",
    "    processor, cache_dir=CACHE_PATH, max_pos_length=MAX_POS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10000000.0\n"
     ]
    }
   ],
   "source": [
    "print(BATCH_SIZE_PER_GPU*NUM_GPUS)\n",
    "print(MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 250/80000 [00:51<4:42:18,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 14/06/2020 11:29:48, average loss: 7.481438, time duration: 51.651358,\n",
      "                            number of examples in current reporting: 250, step 250\n",
      "                            out of total 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|          | 500/80000 [01:42<4:34:13,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 14/06/2020 11:30:39, average loss: 5.455443, time duration: 51.243437,\n",
      "                            number of examples in current reporting: 250, step 500\n",
      "                            out of total 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|          | 750/80000 [02:34<4:31:12,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 14/06/2020 11:31:31, average loss: 4.980248, time duration: 51.195238,\n",
      "                            number of examples in current reporting: 250, step 750\n",
      "                            out of total 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|▏         | 1000/80000 [03:25<4:38:38,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 14/06/2020 11:32:22, average loss: 4.739387, time duration: 51.339610,\n",
      "                            number of examples in current reporting: 250, step 1000\n",
      "                            out of total 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 1250/80000 [04:16<4:36:18,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 14/06/2020 11:33:13, average loss: 4.552084, time duration: 51.054695,\n",
      "                            number of examples in current reporting: 250, step 1250\n",
      "                            out of total 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 1303/80000 [04:27<4:24:07,  4.97it/s]"
     ]
    }
   ],
   "source": [
    "summarizer.fit(\n",
    "    train_dataset,\n",
    "    num_gpus=NUM_GPUS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_steps=MAX_STEPS,\n",
    "    learning_rate_bert=LEARNING_RATE_BERT,\n",
    "    learning_rate_dec=LEARNING_RATE_DEC,\n",
    "    warmup_steps_bert=WARMUP_STEPS_BERT,\n",
    "    warmup_steps_dec=WARMUP_STEPS_DEC,\n",
    "    save_every=SAVE_EVERY,\n",
    "    report_every=REPORT_EVERY,\n",
    "    fp16=FP16,\n",
    "    # checkpoint=\"saved checkpoint path\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "saving through pytorch to /home/ubuntu/bertsumabs.pt\n"
     ]
    }
   ],
   "source": [
    "summarizer.save_model(MAX_STEPS, os.path.join(\"/home/ubuntu/\", \"bertsumabs.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "To run rouge evaluation, please refer to the section of compute_rouge_perl in [summarization_evaluation.ipynb](summarization_evaluation.ipynb) for setup.\n",
    "For the settings in this notebook with QUICK_RUN=False, you should get ROUGE scores close to the following numbers: <br />\n",
    "``\n",
    "{'rouge-1': {'f': 0.34819639878321873,\n",
    "             'p': 0.39977932634737307,\n",
    "             'r': 0.34429079596863604},\n",
    " 'rouge-2': {'f': 0.13919271352557894,\n",
    "             'p': 0.16129965067780644,\n",
    "             'r': 0.1372938054050938},\n",
    " 'rouge-l': {'f': 0.2313282318854973,\n",
    "             'p': 0.26664667422849747,\n",
    "             'r': 0.22850294283399628}}\n",
    " ``\n",
    " \n",
    " Better performance can be achieved by increasing the MAX_STEPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# checkpoint = torch.load(os.path.join(CACHE_PATH, \"bertsumabs.pt\"), map_location=\"cpu\")\n",
    "# summarizer = BertSumAbs(\n",
    "#     processor, cache_dir=CACHE_PATH, max_pos_length=MAX_POS, test=True\n",
    "# )\n",
    "# summarizer.model.load_checkpoint(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length is 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary:  10%|█         | 1/10 [00:03<00:28,  3.17s/it]\u001b[A\n",
      "Generating summary:  20%|██        | 2/10 [00:06<00:25,  3.14s/it]\u001b[A\n",
      "Generating summary:  30%|███       | 3/10 [00:09<00:21,  3.13s/it]\u001b[A\n",
      "Generating summary:  40%|████      | 4/10 [00:12<00:18,  3.15s/it]\u001b[A\n",
      "Generating summary:  50%|█████     | 5/10 [00:15<00:15,  3.14s/it]\u001b[A\n",
      "Generating summary:  60%|██████    | 6/10 [00:18<00:12,  3.12s/it]\u001b[A\n",
      "Generating summary:  70%|███████   | 7/10 [00:21<00:09,  3.11s/it]\u001b[A\n",
      "Generating summary:  80%|████████  | 8/10 [00:24<00:06,  3.10s/it]\u001b[A\n",
      "Generating summary:  90%|█████████ | 9/10 [00:27<00:03,  3.10s/it]\u001b[A\n",
      "Generating summary: 100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "TEST_TOP_N = 10\n",
    "if not QUICK_RUN:\n",
    "    TEST_TOP_N = len(test_dataset)\n",
    "TEST_TOP_N = 10\n",
    "if NUM_GPUS:\n",
    "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
    "else:\n",
    "    BATCH_SIZE = 1\n",
    "    \n",
    "shortened_dataset = test_dataset.shorten(top_n=TEST_TOP_N)\n",
    "src = shortened_dataset.get_source()\n",
    "reference_summaries = [\" \".join(t).rstrip(\"\\n\") for t in shortened_dataset.get_target()]\n",
    "generated_summaries = summarizer.predict(\n",
    "    shortened_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS\n",
    ")\n",
    "assert len(generated_summaries) == len(reference_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abraham Bredius wurde am 18.',\n",
       " 'April 1855 in Amsterdam geboren.',\n",
       " 'Sein Vater Johannes Jacobus Bredius war Direktor einer Fabrik, in der Schiesspulver hergestellt wurde, so dass Abraham Bredius in Wohlstand aufwuchs.',\n",
       " 'Der Familie gehörte eine Sammlung von Gemälden aus dem Goldenen Zeitalter der Niederlande und chinesischem Porzellan.',\n",
       " 'Als Abraham Bredius zehn Jahre alt war, verstarb seine Mutter.',\n",
       " 'Erst wollte er Pianist werden, brach nach drei Jahren das Studium jedoch ab, weil er seine Chancen in diesem Beruf schlecht einschätzte.',\n",
       " 'Abraham Bredius erhielt 1878 die Erlaubnis seines Vaters, nach Italien zu reisen.',\n",
       " 'Dort lernte er die italienische Kunst kennen.',\n",
       " 'Bredius traf in Florenz Wilhelm Bode, den Direktor der Berliner Museen, der ihn dazu veranlasste, die Kunst seines Heimatlandes in den Fokus seiner Studien zu stellen.',\n",
       " 'Dabei legte er den Schwerpunkt auf die Malerei des 17.',\n",
       " 'Jahrhunderts, die er aus seiner Familie heraus schon kannte, und reiste durch ganz Europa, um Sammlungen zu besuchen.',\n",
       " 'Daneben konzentrierte er sich auf Archivarbeit, die ein besonderes Kennzeichen seiner Arbeit wurde.',\n",
       " 'Er veröffentlichte mehrere Artikel im \"Nederlandsche Spectator\", was ihm Aufmerksamkeit eintrug.',\n",
       " 'Deshalb wurde er 1880 als stellvertretender Direktor an das Nederlandsch Museum voor Geschiedenis en Kunst in Den Haag, das fünf Jahre später dem Rijksmuseum Amsterdam angegliedert wurde, berufen.',\n",
       " 'Seine Aufgabe war es, die dortige Sammlung zu katalogisieren.',\n",
       " 'Abraham Bredius machte sich einen Namen als Experte für Jan Vermeer, als er 1883 eine Zuschreibung durch Théophile Thoré in einer Publikation als \"Ein pseudo-Vermeer\" bezeichnete.',\n",
       " '1888 verliess Bredius das Rijksmuseum, als ihm die Universität Giessen einen Doktortitel verlieh.',\n",
       " 'Ein weiterer wurde ihm in Krakau verliehen.',\n",
       " 'Bredius wurde 1889 zum Direktor des Mauritshuis in Den Haag ernannt und setzte sich damit gegen Victor de Stuers durch, der im Innenministerium für Kunst zuständig war.',\n",
       " '1891 wurde Cornelis Hofstede de Groot sein Stellvertreter, mit dem Bredius zum Teil schwere Auseinandersetzungen hatte, über die er bis 1896 mehrmals die Zeitungen informierte.',\n",
       " '1895 veröffentlichten beide trotz allem einen neuen Katalog der Werke des Mauritshuis.',\n",
       " 'Unter der Leitung Bredius erlangte das Museum internationalen Ruhm.',\n",
       " 'Zudem ergänzte er die Sammlung mit 30 Erwerbungen.',\n",
       " '1909 verliess er das Mauritshuis mit der Begründung, dass sich sein Gesundheitszustand verschlechtert habe.',\n",
       " 'Sein Nachfolger wurde Wilhelm Martin.',\n",
       " 'Danach setzte Abraham Bredius seine Reisetätigkeit fort, bei der er zum Beispiel das Gemälde \"Der polnische Reiter\" von Rembrandt van Rijn entdeckt hatte.',\n",
       " 'So reiste er 1913 und 1914 durch die Vereinigten Staaten.',\n",
       " 'Zudem veröffentlichte er Artikel in der Zeitung \"Oud-Holland\", deren Mitherausgeber er war.',\n",
       " '1922 zog Abraham Bredius nach Monte Carlo, um Steuern zu sparen.',\n",
       " '1937 bescheinigte er der Fälschung \"Christus in Emmaus\" von Han van Meegeren, dass sie ein authentisches Werk Jan Vermeers sei.',\n",
       " 'Zwar schrieben auch andere Kunsthistoriker die Fälschung Vermeer zu, doch Bredius veröffentlichte im Burlington Magazine einen sehr enthusiastischen Artikel.',\n",
       " 'Nach seinem Tod am 13.',\n",
       " 'März 1946 erwarb die Stadt Den Haag die Privatsammlung Bredius und unterhält im früheren Wohnhaus des Sammlers mit dem Museum Bredius ein eigenes Museum für die Sammlung.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_dataset.get_source()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'albert kardinal war ein deutscher schriftsteller .  war er war er ist er war ein italienischer komponist .   fur den jahrhundert .  er wurde er wurde .  .  die er wurde sie .             .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(CACHE_PATH):\n",
    "    shutil.rmtree(CACHE_PATH, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}